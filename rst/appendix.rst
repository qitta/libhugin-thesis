.. raw:: latex

   \appendix


.. _http_benchmark:

Anhang A (Httplib Benchmark)
============================

Das folgende Code--Snippet wurde zum Benchmarken der unterschiedlichen Python
HTTP--Bibliotheken verwendet.

.. literalinclude:: ./attachments/httplib_test.py
   :language: python


.. _string_comparsion_algorithms:

Anhang B (Analyse Zeichenkettenvergleich)
=========================================

Das folgende Code--Snippet wurde zum Benchmarken von unterschiedlichen
Zeichenkettenvergleichsalgorithmen verwendet.

.. literalinclude:: ./attachments/strcmp_benchmark.py
   :language: python


.. _source_response:

Anhang C (Antwortzeiten Http Metadatenquellen)
==============================================

Das folgende Code--Snippet wurde zum Benchmarken von unterschiedlichen
Antwortzeiten der Online--Plattformen verwendet.

.. literalinclude:: ./attachments/download_perf_benchmark.py
   :language: python


.. _libhugin_source_response:

Anhang D (Antwortzeiten Libhugin Metadatenquellen)
==================================================

Das folgende Code--Snippet wurde zum Benchmarken der Abfragegeschwindigkeit von
*libhugin* verwendet.

.. literalinclude:: ./attachments/libhugin_download_pref_benchmark.py
   :language: python


.. _gewichtetes_rating:

Anhang E (Gewichtetes Rating)
=============================

Das folgende Code--Snippet wurde zur gewichteten Rating--Ermittlung verwendet:

.. literalinclude:: ./attachments/year_penalty.py
   :language: python


.. _imdblookup_script:

Anhang F (IMDB Title Lookup)
============================

Das folgende Code--Snippet wurde zum Beschaffen der Metadaten verwendet:

.. literalinclude:: ./attachments/imdblookup.py
   :language: python


.. _timeout:

Anhang G (Timeoutverhalten)
===========================

Das folgende Code--Snippet wurde für den Timeout--Test verwendet:

.. literalinclude:: ./attachments/timeout.py
   :language: python


.. _hugin_search_benchmark:

Anhang H (Libhugin Threaded Downloadgeschwindigkeit)
====================================================

Das folgende Code--Snippet wurde für den Threaded--Search--Benchmark verwendet:

.. literalinclude:: ./attachments/hugin_search_benchmark.py
   :language: python


.. _genre-table:

Anhang I (Genre Analyse)
========================

Das folgende Code--Snippet wurde für die Analyse der Genreinformationen verwendet:

.. literalinclude:: ./attachments/analyze.py
   :language: python


.. _code_yeardiff:

Anhang J (Differenz Erscheinungsjahr)
=====================================

Das folgende Code--Snippet wurde für die Analyse der Erscheinungsjahr--Differenzen
verwendet:

.. literalinclude:: ./attachments/yeardiff.py
   :language: python


.. _rating:

Anhang K (Ratingverteilung)
============================

Das folgende Code--Snippet wurde für die Analyse der Ratingverteilung in der
Stichprobe verwendet:

.. literalinclude:: ./attachments/rating.py
   :language: python


.. _completness:

Anhang L (Unvollständigkeit Metadaten)
======================================

Das folgende Code--Snippet wurde für die Analyse der Unvollständigkeit der
Metadaten verwendet:

.. literalinclude:: ./attachments/completeness.py
   :language: python


.. _gil-limitation:

Anhang M (GIL Limitierung)
==========================

Das folgende Code--Snippet wurde verwendet, um die GIL--Limitierung bei
CPU--abhängigen Aufgaben zu messen:

.. literalinclude:: ./attachments/gil_limitation_bench.py
   :language: python


.. _comparsion-rating:

Anhang N (Rating Differenz)
===========================

Das folgende Code--Snippet wurde verwendet um Vergleichswerte zwischen
Damerau--Levenshtein und Ratcliff--Obershelp zu ermitteln.

.. literalinclude:: ./attachments/comparsion_rating.py
   :language: python


.. _utils:

Anhang O (Utils)
================

Die Funktion im folgenden Code--Snippet wird von Skripten zum Einlesen der
Metadaten verwendet:

.. literalinclude:: ./attachments/comparsion_rating.py
   :language: python
